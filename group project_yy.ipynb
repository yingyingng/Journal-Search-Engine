{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "560748dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To maximise the accuracy of your search, please provide as much information as you have for the following fields. However, you may skip if you do not have any requirements for the field. If you have more than 1 piece of information that you would like to include in each field, simply include a comma between them. Let's begin the search!\n",
      "First or last name of author:goh\n",
      "Name of journal:aslib\n",
      "Title of article:\n",
      "Keyword(s):\n",
      "Do you want to include all or any of the above fields? All/Any:\n",
      "Please enter a range for year between 1995 and 2021:\n",
      "Please enter a range between 0 to 99 for the number of pages:\n",
      "Does the article need a corresponding author? Yes/No:\n",
      "##################################################################################################################\n",
      "There are 15 articles found:\n",
      "1.Past debates, fresh impact on nano-enabled food: a multigroup comparison of presumed media influence model based on spillover effects of attitude toward genetically modified food\n",
      "2.Information literacy skills of secondary school students in singapore\n",
      "3.Creative information seeking: part ii: empirical verification\n",
      "4.Geogdl: a web-based approach to geography examination revision\n",
      "5.Creative information seeking part i: a conceptual framework\n",
      "6.Does kfc sell rat? analysis of tweets in the wake of a rumor outbreak\n",
      "7.Tiles: classifying contextual information for mobile tourism applications\n",
      "8.Let’s nab fake science news: predicting scientists’ support for interventions using the influence of presumed media influence model\n",
      "9.Small departures, big continuities?: norms, values, and routines in the guardian's big data journalism\n",
      "10.Public engagement by researchers of different disciplines in singapore : a qualitative comparison of macro‐ and meso‐level concerns\n",
      "11.A java-based digital library portal for geography education\n",
      "12.G-portal – a cross disciplinary digital library research program from singapore\n",
      "13.On organizing and accessing geospatial and georeferenced web resources using the g-portal system\n",
      "14.Applying scenario-based design and claims analysis to the design of a digital library of geography examination resources\n",
      "15.Scientists as public communicators: individual- and institutional-level motivations and barriers for public communication in singapore\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open(\"master.json\", encoding=\"utf8\")\n",
    "\n",
    "publications = json.loads(f.read())\n",
    "\n",
    "\n",
    "def create_author_dict(publications):\n",
    "    author_dict = {}\n",
    "    for p in publications:\n",
    "        for a in p[\"authors\"]:\n",
    "            fullname = a[\"fname\"].lower() + a[\"lname\"].lower()\n",
    "            if fullname not in author_dict.keys():\n",
    "                author_dict.update({fullname.lower():[]})\n",
    "                author_dict[fullname.lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "            else:\n",
    "                author_dict[fullname.lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "    return(author_dict)\n",
    "\n",
    "\n",
    "def create_keyword_dict(publications):\n",
    "    keyword_dict = {}\n",
    "    for p in publications:\n",
    "        for k in p[\"paper\"][\"keywords\"]:\n",
    "            if k.lower() not in keyword_dict.keys():\n",
    "                keyword_dict.update({k.lower():[]})\n",
    "                keyword_dict[k.lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "            else:\n",
    "                keyword_dict[k.lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "    return(keyword_dict)\n",
    "\n",
    "    \n",
    "def create_journal_dict(publications):\n",
    "    journal_dict = {}\n",
    "    for p in publications: \n",
    "        if p[\"source\"][\"journal\"].lower() not in journal_dict.keys():\n",
    "            journal_dict.update({p[\"source\"][\"journal\"].lower():[]})\n",
    "            journal_dict[p[\"source\"][\"journal\"].lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "        else:\n",
    "            journal_dict[p[\"source\"][\"journal\"].lower()].append(p[\"paper\"][\"title\"].lower())\n",
    "    return(journal_dict)\n",
    "\n",
    "def create_title_list(publications):\n",
    "    title_list = []\n",
    "    for p in publications:\n",
    "        title_list.append(p[\"paper\"][\"title\"].lower())\n",
    "    return(title_list)\n",
    "\n",
    "def pages_error(publications):\n",
    "    for p in publications:\n",
    "        try:\n",
    "            int(p[\"source\"][\"pages\"][\"s_page\"])\n",
    "            int(p[\"source\"][\"pages\"][\"e_page\"])\n",
    "        except KeyError:\n",
    "            p[\"source\"][\"pages\"] = {\"s_page\":0, \"e_page\":0}\n",
    "        except TypeError:\n",
    "            p[\"source\"][\"pages\"][\"s_page\"] = 0\n",
    "            p[\"source\"][\"pages\"][\"e_page\"] = 0\n",
    "    return publications\n",
    "\n",
    "\n",
    "def cauthor_error(publications):\n",
    "    for p in publications:\n",
    "        for a in p[\"authors\"]:\n",
    "            try:\n",
    "                a[\"cauthor\"]\n",
    "            except KeyError:\n",
    "                a[\"cauthor\"] = False\n",
    "    return publications\n",
    "\n",
    "def corr(publications):\n",
    "    for p in publications:\n",
    "        for a in p[\"authors\"]:\n",
    "            if a[\"cauthor\"] == True:\n",
    "                p[\"corr\"] = True\n",
    "        p.setdefault(\"corr\", False)\n",
    "    return publications\n",
    "\n",
    "\n",
    "def create_title_dict(publications):\n",
    "    title_dict = {}\n",
    "    for p in publications:\n",
    "        if p[\"paper\"][\"title\"].lower() not in title_dict.keys():\n",
    "            title_dict[p[\"paper\"][\"title\"].lower()]={\"year\":p[\"year\"],\"num_page\": p[\"source\"][\"pages\"][\"e_page\"]-p[\"source\"][\"pages\"][\"s_page\"]+1, \"corr\": p[\"corr\"]}\n",
    "    return title_dict\n",
    "\n",
    "\n",
    "def sanitise_year(): \n",
    "    while True:\n",
    "        year = input(\"Please enter a range for year between 1995 and 2021:\").split(\"-\")\n",
    "        if year != [\"\"]:\n",
    "            try:\n",
    "                year_int = [int(i) for i in year]\n",
    "                if len(year_int) == 2:\n",
    "                    break\n",
    "                elif len(year_int) == 1:\n",
    "                    for i in year_int:\n",
    "                        return [i,i+1]\n",
    "                        break\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid range.\")\n",
    "        else:\n",
    "            year_int = [1995,2021]\n",
    "            break\n",
    "    return year_int\n",
    "\n",
    "def sanitise_pages(): \n",
    "    while True:\n",
    "        pages = input(\"Please enter a range between 0 to 99 for the number of pages:\").split(\"-\")\n",
    "        if pages != [\"\"]:\n",
    "            try:\n",
    "                pages_int = [int(i) for i in pages]\n",
    "                if len(pages_int) == 2:\n",
    "                    break\n",
    "                elif len(pages_int) == 1:\n",
    "                    for i in pages_int:\n",
    "                        return [i, i+1]\n",
    "                        break\n",
    "            except ValueError:\n",
    "                print(\"Please enter a valid range.\")\n",
    "        else:\n",
    "            pages_int = [0,99]\n",
    "            break\n",
    "    return pages_int\n",
    "\n",
    "def sanitise_corr_author():\n",
    "    corr_author = input(\"Does the article need a corresponding author? Yes/No:\").lower()\n",
    "    if corr_author in [\"yes\",\"no\"]:\n",
    "        cl = [True if corr_author == \"yes\" else False]\n",
    "    else:\n",
    "        cl = [True,False]\n",
    "    return cl\n",
    "            \n",
    "def menu():\n",
    "    print(\"To maximise the accuracy of your search, please provide as much information as you have for the following fields. However, you may skip if you do not have any requirements for the field. If you have more than 1 piece of information that you would like to include in each field, simply include a comma between them. Let's begin the search!\")\n",
    "    field_list = []\n",
    "    author = input(\"First or last name of author:\").lower().split(\",\")\n",
    "    journal = input(\"Name of journal:\").lower().split(\",\")\n",
    "    title = input(\"Title of article:\").lower().split(\",\")\n",
    "    keyword = input(\"Keyword(s):\").lower().split(\",\")\n",
    "    field_list = [author, journal, title, keyword] #note order\n",
    "    any_or_all = input(\"Do you want to include all or any of the above fields? All/Any:\").lower() or \"any\"\n",
    "    if any_or_all in [\"all\", \"any\"]:\n",
    "        pass\n",
    "    else:\n",
    "        any_or_all == \"any\"\n",
    "    filter_list = []\n",
    "    y = sanitise_year()\n",
    "    p = sanitise_pages()\n",
    "    c = sanitise_corr_author()\n",
    "    filter_list = [y, p, c]\n",
    "    return(field_list, any_or_all, filter_list)\n",
    "\n",
    "\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def search(d, i):\n",
    "    res = [val for key,val in d.items() if i in key]\n",
    "    res = set(flatten(res))\n",
    "    return(res) \n",
    "\n",
    "def search_author(field_list):\n",
    "    if field_list != ['']:\n",
    "        for i in field_list:\n",
    "            res1 = search(author_dict,i)\n",
    "    else:\n",
    "        res1 = set()\n",
    "    return res1\n",
    "\n",
    "def search_journal(field_list):\n",
    "    if field_list != ['']:\n",
    "        for i in field_list:\n",
    "            res2 = search(journal_dict,i)  \n",
    "    else:\n",
    "        res2= set()\n",
    "    return res2\n",
    "\n",
    "def search_title(field_list):\n",
    "    if field_list != ['']:\n",
    "        for i in field_list:\n",
    "            res3 = set([t for t in title_list if i in t])\n",
    "    else:\n",
    "        res3 = set()\n",
    "    return res3\n",
    "\n",
    "def search_keyword(field_list):\n",
    "    if field_list != ['']:\n",
    "        for i in field_list:\n",
    "            res4 = search(keyword_dict,i)\n",
    "    else:\n",
    "        res4 = set()\n",
    "    return res4\n",
    "\n",
    "def to_map(f,n):\n",
    "    return f(n)\n",
    "\n",
    "def combine_search(field_list, any_or_all):\n",
    "    allf = [search_author, search_journal, search_title, search_keyword]\n",
    "    r = list(map(to_map, allf, field_list))\n",
    "    results = list(filter(lambda x: bool(x), r))\n",
    "    if any_or_all == \"all\":\n",
    "        final = results[0].intersection(*results)\n",
    "    else:\n",
    "        final = results[0].union(*results)\n",
    "    return final\n",
    "\n",
    "def pages_year_filter(title_dict, final, filter_list):\n",
    "    fres = []\n",
    "    for i in final:\n",
    "            conditions = [title_dict[i]['year'] in range(filter_list[0][0], filter_list[0][1]),title_dict[i]['num_page'] in range(filter_list[1][0], filter_list[1][1]), title_dict[i][\"corr\"] in filter_list[2]]\n",
    "            if all(conditions):\n",
    "                fres.append(i)\n",
    "    print(f\"There are {len(fres)} articles found:\")\n",
    "    for i,n in enumerate(fres,start=1):\n",
    "        print(f\"{i}.{n.capitalize()}\")\n",
    "\n",
    "def main():\n",
    "    author_dict = create_author_dict(publications)\n",
    "    keyword_dict = create_keyword_dict(publications)\n",
    "    journal_dict = create_journal_dict(publications)\n",
    "    title_list = create_title_list(publications)\n",
    "    publications_pc = pages_error(publications)\n",
    "    publications_cc = cauthor_error(publications_pc)\n",
    "    publications_final = corr(publications_cc)\n",
    "    title_dict = create_title_dict(publications_final)\n",
    "    all_searches = menu()\n",
    "    filter_list = all_searches[2]\n",
    "    print(\"##################################################################################################################\")\n",
    "    final = combine_search(all_searches[0], all_searches[1])\n",
    "    pages_year_filter(title_dict, final, all_searches[2])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc660ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
